{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Dataframes and Processing in Chunks\n",
    "\n",
    "In this project, I will be working with chunked dataframes and optimizing a dataframe's memory usage. I will be working with financial lending data from [Lending Club](https://www.lendingclub.com/), which is a marketplace for personal loans that matches borrowers and investors. The website lists approved loans, so investors can view information about the loan. This information includes borrower's credit score, the purpose of the loan, and other details in the loan applications. \n",
    "\n",
    "The specific dataset I will be using includes loans approved from 2007 through 2011, which can be downloaded [here](https://www.lendingclub.com/auth/login?login_url=%2Fstatistics%2Fadditional-statistics%3F). \n",
    "\n",
    "Reading in the entire dataset would consume about 67 megabytes of memory, and the assumption is that I would have only 10 megabytes of memory available throughout the project. \n",
    "\n",
    "## Exploring the data\n",
    "\n",
    "First, I will read in the first five lines from `loans_2007.csv` to look for any data quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_title</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>issue_d</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>title</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>earliest_cr_line</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>out_prncp</th>\n",
       "      <th>out_prncp_inv</th>\n",
       "      <th>total_pymnt</th>\n",
       "      <th>total_pymnt_inv</th>\n",
       "      <th>total_rec_prncp</th>\n",
       "      <th>total_rec_int</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>recoveries</th>\n",
       "      <th>collection_recovery_fee</th>\n",
       "      <th>last_pymnt_d</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>n</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>Computer</td>\n",
       "      <td>860xx</td>\n",
       "      <td>AZ</td>\n",
       "      <td>27.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-1985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13648.0</td>\n",
       "      <td>83.7%</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5863.155187</td>\n",
       "      <td>5833.84</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>863.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2015</td>\n",
       "      <td>171.62</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>Ryder</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Charged Off</td>\n",
       "      <td>n</td>\n",
       "      <td>car</td>\n",
       "      <td>bike</td>\n",
       "      <td>309xx</td>\n",
       "      <td>GA</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apr-1999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>9.4%</td>\n",
       "      <td>4.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1008.710000</td>\n",
       "      <td>1008.71</td>\n",
       "      <td>456.46</td>\n",
       "      <td>435.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117.08</td>\n",
       "      <td>1.11</td>\n",
       "      <td>Apr-2013</td>\n",
       "      <td>119.66</td>\n",
       "      <td>Sep-2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>n</td>\n",
       "      <td>small_business</td>\n",
       "      <td>real estate business</td>\n",
       "      <td>606xx</td>\n",
       "      <td>IL</td>\n",
       "      <td>8.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov-2001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2956.0</td>\n",
       "      <td>98.5%</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3005.666844</td>\n",
       "      <td>3005.67</td>\n",
       "      <td>2400.00</td>\n",
       "      <td>605.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jun-2014</td>\n",
       "      <td>649.91</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>AIR RESOURCES BOARD</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>n</td>\n",
       "      <td>other</td>\n",
       "      <td>personel</td>\n",
       "      <td>917xx</td>\n",
       "      <td>CA</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb-1996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5598.0</td>\n",
       "      <td>21%</td>\n",
       "      <td>37.0</td>\n",
       "      <td>f</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12231.890000</td>\n",
       "      <td>12231.89</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>2214.92</td>\n",
       "      <td>16.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jan-2015</td>\n",
       "      <td>357.48</td>\n",
       "      <td>Apr-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>University Medical Group</td>\n",
       "      <td>1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Dec-2011</td>\n",
       "      <td>Current</td>\n",
       "      <td>n</td>\n",
       "      <td>other</td>\n",
       "      <td>Personal</td>\n",
       "      <td>972xx</td>\n",
       "      <td>OR</td>\n",
       "      <td>17.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jan-1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27783.0</td>\n",
       "      <td>53.9%</td>\n",
       "      <td>38.0</td>\n",
       "      <td>f</td>\n",
       "      <td>461.73</td>\n",
       "      <td>461.73</td>\n",
       "      <td>3581.120000</td>\n",
       "      <td>3581.12</td>\n",
       "      <td>2538.27</td>\n",
       "      <td>1042.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>67.79</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
       "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
       "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
       "2  1077175  1313524.0     2400.0       2400.0           2400.0   36 months   \n",
       "3  1076863  1277178.0    10000.0      10000.0          10000.0   36 months   \n",
       "4  1075358  1311748.0     3000.0       3000.0           3000.0   60 months   \n",
       "\n",
       "  int_rate  installment grade sub_grade                 emp_title emp_length  \\\n",
       "0   10.65%       162.87     B        B2                       NaN  10+ years   \n",
       "1   15.27%        59.83     C        C4                     Ryder   < 1 year   \n",
       "2   15.96%        84.33     C        C5                       NaN  10+ years   \n",
       "3   13.49%       339.31     C        C1       AIR RESOURCES BOARD  10+ years   \n",
       "4   12.69%        67.79     B        B5  University Medical Group     1 year   \n",
       "\n",
       "  home_ownership  annual_inc verification_status   issue_d  loan_status  \\\n",
       "0           RENT     24000.0            Verified  Dec-2011   Fully Paid   \n",
       "1           RENT     30000.0     Source Verified  Dec-2011  Charged Off   \n",
       "2           RENT     12252.0        Not Verified  Dec-2011   Fully Paid   \n",
       "3           RENT     49200.0     Source Verified  Dec-2011   Fully Paid   \n",
       "4           RENT     80000.0     Source Verified  Dec-2011      Current   \n",
       "\n",
       "  pymnt_plan         purpose                 title zip_code addr_state    dti  \\\n",
       "0          n     credit_card              Computer    860xx         AZ  27.65   \n",
       "1          n             car                  bike    309xx         GA   1.00   \n",
       "2          n  small_business  real estate business    606xx         IL   8.72   \n",
       "3          n           other              personel    917xx         CA  20.00   \n",
       "4          n           other              Personal    972xx         OR  17.94   \n",
       "\n",
       "   delinq_2yrs earliest_cr_line  inq_last_6mths  open_acc  pub_rec  revol_bal  \\\n",
       "0          0.0         Jan-1985             1.0       3.0      0.0    13648.0   \n",
       "1          0.0         Apr-1999             5.0       3.0      0.0     1687.0   \n",
       "2          0.0         Nov-2001             2.0       2.0      0.0     2956.0   \n",
       "3          0.0         Feb-1996             1.0      10.0      0.0     5598.0   \n",
       "4          0.0         Jan-1996             0.0      15.0      0.0    27783.0   \n",
       "\n",
       "  revol_util  total_acc initial_list_status  out_prncp  out_prncp_inv  \\\n",
       "0      83.7%        9.0                   f       0.00           0.00   \n",
       "1       9.4%        4.0                   f       0.00           0.00   \n",
       "2      98.5%       10.0                   f       0.00           0.00   \n",
       "3        21%       37.0                   f       0.00           0.00   \n",
       "4      53.9%       38.0                   f     461.73         461.73   \n",
       "\n",
       "    total_pymnt  total_pymnt_inv  total_rec_prncp  total_rec_int  \\\n",
       "0   5863.155187          5833.84          5000.00         863.16   \n",
       "1   1008.710000          1008.71           456.46         435.17   \n",
       "2   3005.666844          3005.67          2400.00         605.67   \n",
       "3  12231.890000         12231.89         10000.00        2214.92   \n",
       "4   3581.120000          3581.12          2538.27        1042.85   \n",
       "\n",
       "   total_rec_late_fee  recoveries  collection_recovery_fee last_pymnt_d  \\\n",
       "0                0.00        0.00                     0.00     Jan-2015   \n",
       "1                0.00      117.08                     1.11     Apr-2013   \n",
       "2                0.00        0.00                     0.00     Jun-2014   \n",
       "3               16.97        0.00                     0.00     Jan-2015   \n",
       "4                0.00        0.00                     0.00     Jun-2016   \n",
       "\n",
       "   last_pymnt_amnt last_credit_pull_d  collections_12_mths_ex_med  \\\n",
       "0           171.62           Jun-2016                         0.0   \n",
       "1           119.66           Sep-2013                         0.0   \n",
       "2           649.91           Jun-2016                         0.0   \n",
       "3           357.48           Apr-2016                         0.0   \n",
       "4            67.79           Jun-2016                         0.0   \n",
       "\n",
       "   policy_code application_type  acc_now_delinq  chargeoff_within_12_mths  \\\n",
       "0          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "1          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "2          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "3          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "4          1.0       INDIVIDUAL             0.0                       0.0   \n",
       "\n",
       "   delinq_amnt  pub_rec_bankruptcies  tax_liens  \n",
       "0          0.0                   0.0        0.0  \n",
       "1          0.0                   0.0        0.0  \n",
       "2          0.0                   0.0        0.0  \n",
       "3          0.0                   0.0        0.0  \n",
       "4          0.0                   0.0        0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 99\n",
    "\n",
    "loans_5 = pd.read_csv('loans_2007.csv', nrows=5)\n",
    "loans_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculating memory usage\n",
    "\n",
    "Next, I will look at the first 1000 rows to calculate the total memory usage for these rows. The result will print in bytes, so I will convert this to megabytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of 1000 rows (in megabytes):\n",
      "\n",
      "1.5502090454101562\n"
     ]
    }
   ],
   "source": [
    "loans_1000 = pd.read_csv('loans_2007.csv', nrows=1000)\n",
    "mem_bytes = loans_1000.memory_usage(deep=True).sum()\n",
    "mem_megabytes = mem_bytes/(2**20)\n",
    "print(\"Memory usage of 1000 rows (in megabytes):\\n\")\n",
    "print(mem_megabytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have determined the memory usage for 1000 rows to be about 1.55 megabytes, I will try different number of rows until I converge on a memory usage under five megabytes (to stay on the conservative side). I will try 3 times the original number of rows I tried, 3000 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Megabytes of total memory usage in each chunk:\n",
      "\n",
      "4.649013519287109\n",
      "4.6447601318359375\n",
      "4.646517753601074\n",
      "4.647870063781738\n",
      "4.6440629959106445\n",
      "4.6459455490112305\n",
      "4.644536972045898\n",
      "4.646905899047852\n",
      "4.645031929016113\n",
      "4.645082473754883\n",
      "4.657794952392578\n",
      "4.6566619873046875\n",
      "4.663469314575195\n",
      "4.896910667419434\n",
      "0.8808088302612305\n",
      "\n",
      "Total memory usage across all chunks:\n",
      "66.2153730392456\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "print(\"Megabytes of total memory usage in each chunk:\\n\")\n",
    "list_mem = []\n",
    "for chunk in chunk_iter:\n",
    "    mem_bytes = chunk.memory_usage(deep=True).sum()\n",
    "    mem_megabytes = mem_bytes/(2**20)\n",
    "    print(mem_megabytes)\n",
    "    list_mem.append(mem_megabytes)\n",
    "\n",
    "print(\"\\nTotal memory usage across all chunks:\")\n",
    "print(sum(list_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of rows:\n",
      "42538\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "num_rows = 0\n",
    "for chunk in chunk_iter:\n",
    "    num_rows = num_rows + len(chunk)\n",
    "print(\"\\nTotal number of rows:\")\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Each one of these memory usage values is below 5 megabytes, so it will work to use a chunk size of 3000 rows for batch processing our dataset.\n",
    "\n",
    "## Distinguishing column types\n",
    "\n",
    "I will now determine the number of numeric-type columns and the number of string-type columns in each chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numeric columns in each chunk:\n",
      "[31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 30, 30]\n",
      "\n",
      "Number of string columns in each chunk:\n",
      "[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22]\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "num_numeric_cols = []\n",
    "for chunk in chunk_iter:\n",
    "    num = len(chunk.select_dtypes(include=['number']).columns)\n",
    "    num_numeric_cols.append(num)\n",
    "print(\"Number of numeric columns in each chunk:\")\n",
    "print(num_numeric_cols)\n",
    "\n",
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "num_string_cols = []\n",
    "for chunk in chunk_iter:\n",
    "    num = len(chunk.select_dtypes(include=['object']).columns)\n",
    "    num_string_cols.append(num)\n",
    "print(\"\\nNumber of string columns in each chunk:\")\n",
    "print(num_string_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the final to chunks have different numbers of numeric columns and string columns than the rest of the chunks. I will determine why this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall string columns: Index(['term', 'int_rate', 'grade', 'sub_grade', 'emp_title', 'emp_length',\n",
      "       'home_ownership', 'verification_status', 'issue_d', 'loan_status',\n",
      "       'pymnt_plan', 'purpose', 'title', 'zip_code', 'addr_state',\n",
      "       'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d',\n",
      "       'last_credit_pull_d', 'application_type'],\n",
      "      dtype='object') \n",
      "\n",
      "Chunk #14\n",
      "String columns: Index(['id', 'term', 'int_rate', 'grade', 'sub_grade', 'emp_title',\n",
      "       'emp_length', 'home_ownership', 'verification_status', 'issue_d',\n",
      "       'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code',\n",
      "       'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status',\n",
      "       'last_pymnt_d', 'last_credit_pull_d', 'application_type'],\n",
      "      dtype='object') \n",
      "\n",
      "Chunk #15\n",
      "String columns: Index(['id', 'term', 'int_rate', 'grade', 'sub_grade', 'emp_title',\n",
      "       'emp_length', 'home_ownership', 'verification_status', 'issue_d',\n",
      "       'loan_status', 'pymnt_plan', 'purpose', 'title', 'zip_code',\n",
      "       'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status',\n",
      "       'last_pymnt_d', 'last_credit_pull_d', 'application_type'],\n",
      "      dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "string_cols = []\n",
    "chunk_num = 0\n",
    "for chunk in chunk_iter:\n",
    "    chunk_num = chunk_num + 1\n",
    "    chunk_string_cols = chunk.select_dtypes(include=['object']).columns\n",
    "    if len(string_cols) > 0:\n",
    "        if len(string_cols) != len(chunk_string_cols):\n",
    "            print('Chunk #' + str(chunk_num))\n",
    "            print('String columns:', chunk_string_cols, '\\n')\n",
    "    else:\n",
    "        string_cols = chunk_string_cols\n",
    "        print('Overall string columns:', string_cols, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in the last two chunks, the first column, `id`, is considered a string, whereas in the first chunk (which is the same as the next 12 chunks), the `id` column is not a string.\n",
    "\n",
    "## Analyzing string columns\n",
    "\n",
    "Next, I will find out how many unique values there are in each string column. To do this, I will have to loop through all string columns, create a dictionary with those column names as keys, and add the number of unique values as the keys in that dictionary. I will also be sure to not count those values which are null, or `NaN`. To view the dictionary clearly, I will import the `json` module and use the `json.dumps()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "uniques = {}\n",
    "nulls = {}\n",
    "for chunk in chunk_iter:\n",
    "    string_cols = chunk.select_dtypes(include=['object'])\n",
    "    cols = string_cols.columns\n",
    "    for c in cols:\n",
    "        uniques[c] = []\n",
    "\n",
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    string_cols = chunk.select_dtypes(include=['object'])\n",
    "    cols = string_cols.columns\n",
    "    for c in cols:\n",
    "        for row in string_cols[c]:\n",
    "            if pd.isnull(row):\n",
    "                null = 'yes'\n",
    "            else:\n",
    "                if row not in uniques[c]:\n",
    "                    uniques[c].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in each string column:\n",
      "\n",
      "{\n",
      "  \"earliest_cr_line\": 530,\n",
      "  \"last_pymnt_d\": 103,\n",
      "  \"addr_state\": 50,\n",
      "  \"zip_code\": 837,\n",
      "  \"term\": 2,\n",
      "  \"title\": 21264,\n",
      "  \"pymnt_plan\": 2,\n",
      "  \"sub_grade\": 35,\n",
      "  \"verification_status\": 3,\n",
      "  \"emp_title\": 30658,\n",
      "  \"home_ownership\": 5,\n",
      "  \"int_rate\": 394,\n",
      "  \"grade\": 7,\n",
      "  \"revol_util\": 1119,\n",
      "  \"application_type\": 1,\n",
      "  \"issue_d\": 55,\n",
      "  \"last_credit_pull_d\": 108,\n",
      "  \"id\": 3538,\n",
      "  \"emp_length\": 11,\n",
      "  \"purpose\": 14,\n",
      "  \"initial_list_status\": 1,\n",
      "  \"loan_status\": 9\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "lengths = {}\n",
    "for column in uniques:\n",
    "    lengths[column] = len(uniques[column])\n",
    "print(\"Number of unique values in each string column:\\n\")\n",
    "print(json.dumps(lengths, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have determined how many unique values there are in each string column, I can determine how many of those string columns contain less than 50% unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"earliest_cr_line\": 42506,\n",
      "  \"last_pymnt_d\": 42452,\n",
      "  \"addr_state\": 42535,\n",
      "  \"zip_code\": 42535,\n",
      "  \"term\": 42535,\n",
      "  \"title\": 42522,\n",
      "  \"pymnt_plan\": 42535,\n",
      "  \"sub_grade\": 42535,\n",
      "  \"verification_status\": 42535,\n",
      "  \"emp_title\": 39909,\n",
      "  \"home_ownership\": 42535,\n",
      "  \"int_rate\": 42535,\n",
      "  \"grade\": 42535,\n",
      "  \"revol_util\": 42445,\n",
      "  \"application_type\": 42535,\n",
      "  \"issue_d\": 42535,\n",
      "  \"last_credit_pull_d\": 42531,\n",
      "  \"id\": 3538,\n",
      "  \"emp_length\": 41423,\n",
      "  \"loan_status\": 42535,\n",
      "  \"initial_list_status\": 42535,\n",
      "  \"purpose\": 42535\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "total_counts = {}\n",
    "for chunk in chunk_iter:\n",
    "    string_cols = chunk.select_dtypes(include=['object'])\n",
    "    cols = string_cols.columns\n",
    "    for c in cols:\n",
    "        total_counts[c] = 0\n",
    "\n",
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    string_cols = chunk.select_dtypes(include=['object'])\n",
    "    cols = string_cols.columns\n",
    "    for c in cols:\n",
    "        for row in string_cols[c]:\n",
    "            if pd.isnull(row):\n",
    "                null = 'yes'\n",
    "            else:\n",
    "                total_counts[c] = total_counts[c] + 1\n",
    "\n",
    "print(json.dumps(total_counts, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have the total counts of each column. Since we have the total counts and the unique counts, we can now create a dictionary with only the accounts where the number of unique counts divided by the number of total counts is less that 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['term', 'int_rate', 'grade', 'sub_grade', 'emp_length', 'home_ownership', 'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'purpose', 'zip_code', 'addr_state', 'earliest_cr_line', 'revol_util', 'initial_list_status', 'last_pymnt_d', 'last_credit_pull_d', 'application_type']\n"
     ]
    }
   ],
   "source": [
    "first_chunk = pd.read_csv('loans_2007.csv', nrows=3000)\n",
    "string_columns = first_chunk.select_dtypes(include=['object'])\n",
    "less_than_half_unique = []\n",
    "for c in string_columns:\n",
    "    percent_unique = lengths[c]/total_counts[c]\n",
    "    if percent_unique < 0.5:\n",
    "        less_than_half_unique.append(c)\n",
    "            \n",
    "print(less_than_half_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Analyzing float columns\n",
    "\n",
    "Next, I can move onto the float columns. I will find out which float columns have no missing values, which means they could be candidates for conversion to integer type. We know from above that the number of rows in the whole dataset is 42538, which is saved in the variable `num_rows`. We can use the same code from above that we used to count the number of non-null rows in the string columns, and then compare that to the expected number of rows to find the number of rows missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"inq_last_6mths\": 32,\n",
      "  \"out_prncp_inv\": 3,\n",
      "  \"policy_code\": 3,\n",
      "  \"total_pymnt_inv\": 3,\n",
      "  \"loan_amnt\": 3,\n",
      "  \"collection_recovery_fee\": 3,\n",
      "  \"total_acc\": 32,\n",
      "  \"total_rec_late_fee\": 3,\n",
      "  \"pub_rec_bankruptcies\": 1368,\n",
      "  \"installment\": 3,\n",
      "  \"recoveries\": 3,\n",
      "  \"funded_amnt_inv\": 3,\n",
      "  \"delinq_amnt\": 32,\n",
      "  \"funded_amnt\": 3,\n",
      "  \"dti\": 3,\n",
      "  \"chargeoff_within_12_mths\": 148,\n",
      "  \"annual_inc\": 7,\n",
      "  \"total_pymnt\": 3,\n",
      "  \"total_rec_prncp\": 3,\n",
      "  \"last_pymnt_amnt\": 3,\n",
      "  \"collections_12_mths_ex_med\": 148,\n",
      "  \"member_id\": 3,\n",
      "  \"tax_liens\": 108,\n",
      "  \"out_prncp\": 3,\n",
      "  \"delinq_2yrs\": 32,\n",
      "  \"open_acc\": 32,\n",
      "  \"pub_rec\": 32,\n",
      "  \"acc_now_delinq\": 32,\n",
      "  \"revol_bal\": 3,\n",
      "  \"total_rec_int\": 3\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "total_counts = {}\n",
    "for chunk in chunk_iter:\n",
    "    float_cols = chunk.select_dtypes(include=['float'])\n",
    "    cols = float_cols.columns\n",
    "    for c in cols:\n",
    "        total_counts[c] = 0\n",
    "\n",
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    float_cols = chunk.select_dtypes(include=['float'])\n",
    "    cols = float_cols.columns\n",
    "    for c in cols:\n",
    "        for row in float_cols[c]:\n",
    "            if pd.isnull(row):\n",
    "                null = 'yes'\n",
    "            else:\n",
    "                total_counts[c] = total_counts[c] + 1\n",
    "\n",
    "num_missing = {}\n",
    "for key in total_counts:\n",
    "    num_missing[key] = num_rows - total_counts[key]\n",
    "    \n",
    "print(json.dumps(num_missing, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting string columns\n",
    "\n",
    "Since I have analyzed the column types as they currently exist, I see that I can now convert some string types to numeric types. I can also convert all columns where the values are less than 50% unique to the category type, and the columns that contain numeric values to the float type. \n",
    "\n",
    "I will start with converting the string columns. It looks like some of the string columns are not useful, and others can be converted to different types. I will go through each column now to determine which ones are necessary, and what types I should change each necessary column to. \n",
    "\n",
    "Columns to remove:\n",
    "\n",
    "* `zip_code` - last two numbers are missing of all zipcodes \n",
    "* `application type` - only one option\n",
    "* `initial_list_status` - only one option\n",
    "* `title` - not consistent\n",
    "* `id` - not consistent\n",
    "\n",
    "Useful columns: \n",
    "\n",
    "* `grade` (category) \n",
    "* `home_ownership` (category)\n",
    "* `emp_length` (category) \n",
    "* `verification_status` (category)\n",
    "* `loan_status` (category)\n",
    "* `addr_state` (category)\n",
    "* `sub_grade` (category)\n",
    "* `purpose` (category)\n",
    "* `earliest_cr_line` (datetime)\n",
    "* `issue_d` (datetime)\n",
    "* `last_pymnt_d` (datetime)\n",
    "* `last_credit_pull_d` (datetime)\n",
    "* `int_rate` (float)\n",
    "* `revol_util` (float)\n",
    "* `pymnt_plan` (boolean)\n",
    "* `term` (numeric)\n",
    "* `emp_title` (string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_cols = ['earliest_cr_line', 'issue_d', 'grade', 'home_ownership', \n",
    "               'last_pymnt_d', 'int_rate', 'emp_length', 'pymnt_plan', \n",
    "               'last_credit_pull_d', 'verification_status','loan_status', \n",
    "               'term', 'addr_state', 'emp_title','revol_util', 'sub_grade',\n",
    "               'purpose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Megabytes of total memory usage in each chunk:\n",
      "\n",
      "0.40640735626220703\n",
      "0.4031820297241211\n",
      "0.40488529205322266\n",
      "0.405303955078125\n",
      "0.40362548828125\n",
      "0.4049654006958008\n",
      "0.4032754898071289\n",
      "0.4050636291503906\n",
      "0.4051513671875\n",
      "0.40613269805908203\n",
      "0.4052286148071289\n",
      "0.40256404876708984\n",
      "0.4092569351196289\n",
      "0.4066162109375\n",
      "0.0806112289428711\n",
      "\n",
      "Total memory usage across all chunks:\n",
      "5.752269744873047\n"
     ]
    }
   ],
   "source": [
    "str_chunks = pd.read_csv('loans_2007.csv', chunksize=3000, usecols=useful_cols,\n",
    "                          parse_dates= ['earliest_cr_line', 'issue_d', \n",
    "                         'last_pymnt_d', 'last_credit_pull_d'])\n",
    "\n",
    "print(\"Megabytes of total memory usage in each chunk:\\n\")\n",
    "list_mem = []\n",
    "for chunk in str_chunks:\n",
    "    chunk['grade'] = chunk['grade'].astype('category')\n",
    "    chunk['home_ownership'] = chunk['home_ownership'].astype('category')\n",
    "    chunk['emp_length'] = chunk['emp_length'].astype('category')\n",
    "    chunk['loan_status'] = chunk['loan_status'].astype('category')\n",
    "    chunk['addr_state'] = chunk['addr_state'].astype('category')\n",
    "    chunk['sub_grade'] = chunk['sub_grade'].astype('category')\n",
    "    chunk['purpose'] = chunk['purpose'].astype('category')\n",
    "    chunk['verification_status'] = chunk['verification_status'].astype('category')\n",
    "    cleaned_int_rate = chunk['int_rate'].str.rstrip(\"%\")\n",
    "    chunk['int_rate'] = pd.to_numeric(cleaned_int_rate)\n",
    "    cleaned_revol_util = chunk['revol_util'].str.rstrip(\"%\")\n",
    "    chunk['revol_util'] = pd.to_numeric(cleaned_revol_util)\n",
    "    cleaned_term = chunk['term'].str.lstrip(\" \").str.rstrip(\" months\")\n",
    "    chunk['term'] = pd.to_numeric(cleaned_term)\n",
    "    chunk['pymnt_plan'] = chunk['pymnt_plan'].astype('bool')\n",
    "    mem_bytes = chunk.memory_usage(deep=True).sum()\n",
    "    mem_megabytes = mem_bytes/(2**20)\n",
    "    print(mem_megabytes)\n",
    "    list_mem.append(mem_megabytes)\n",
    "\n",
    "print(\"\\nTotal memory usage across all chunks:\")\n",
    "print(sum(list_mem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of converting string columns\n",
    "\n",
    "I can see based on these new memory usages that after I have cleaned the data, removed columns that are not useful, and set columns to the appropriate category type, the total memory footprint has decreased to less than 10% of the intial total.\n",
    "\n",
    "\n",
    "## Converting float columns\n",
    "\n",
    "Now, I will move onto converting float columns that contain missing values, and can be changed to a more space efficient type. First, I will have to look at the first few rows of all numeric colummns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                              int64\n",
      "member_id                     float64\n",
      "loan_amnt                     float64\n",
      "funded_amnt                   float64\n",
      "funded_amnt_inv               float64\n",
      "installment                   float64\n",
      "annual_inc                    float64\n",
      "dti                           float64\n",
      "delinq_2yrs                   float64\n",
      "inq_last_6mths                float64\n",
      "open_acc                      float64\n",
      "pub_rec                       float64\n",
      "revol_bal                     float64\n",
      "total_acc                     float64\n",
      "out_prncp                     float64\n",
      "out_prncp_inv                 float64\n",
      "total_pymnt                   float64\n",
      "total_pymnt_inv               float64\n",
      "total_rec_prncp               float64\n",
      "total_rec_int                 float64\n",
      "total_rec_late_fee            float64\n",
      "recoveries                    float64\n",
      "collection_recovery_fee       float64\n",
      "last_pymnt_amnt               float64\n",
      "collections_12_mths_ex_med    float64\n",
      "policy_code                   float64\n",
      "acc_now_delinq                float64\n",
      "chargeoff_within_12_mths      float64\n",
      "delinq_amnt                   float64\n",
      "pub_rec_bankruptcies          float64\n",
      "tax_liens                     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "first_few = pd.read_csv('loans_2007.csv', nrows=10)\n",
    "print(first_few.select_dtypes(include=['number']).dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated earlier, we can leave out the `id` columns. The following columns seem like they can be cast to integers:\n",
    "\n",
    "* `member_id`\n",
    "* `delinq_2yrs`\n",
    "* `inq_last_6mths`\n",
    "* `open_acc`\n",
    "* `public_rec`\n",
    "* `revol_bal`\n",
    "* `total_acc`\n",
    "* `collections_12_mths_ex_med`\n",
    "* `policy_code`  \n",
    "* `acc_now_delinq`\n",
    "* `chargeoff_within_12_mths`  \n",
    "* `delinq_amnt`  \n",
    "* `pub_rec_bankruptcies`  \n",
    "* `tax_liens` \n",
    "\n",
    "The following can still be cast as floats:\n",
    "\n",
    "* `loan_amnt`\n",
    "* `funded_amnt`\n",
    "* `funded_amnt_inv`\n",
    "* `installment`\n",
    "* `annual_inc`\n",
    "* `dti`\n",
    "* `out_prncp`\n",
    "* `out_prncp_inv`\n",
    "* `total_pymnt`\n",
    "* `total_pymnt_inv`\n",
    "* `total_rec_prncp`\n",
    "* `total_rec_int`\n",
    "* `total_rec_late_fee`\n",
    "* `recoveries`\n",
    "* `recovery_collection_fee`\n",
    "* `last_pymnt_amnt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int_cols = ['member_id', 'delinq_2yrs', 'inq_last_6mths', 'open_acc', \n",
    "            'pub_rec', 'revol_bal', 'total_acc', 'collections_12_mths_ex_med',\n",
    "            'policy_code', 'acc_now_delinq', 'chargeoff_within_12_mths', \n",
    "            'delinq_amnt', 'pub_rec_bankruptcies', 'tax_liens']\n",
    "\n",
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000, usecols=int_cols)\n",
    "for chunk in chunk_iter:\n",
    "        for col in int_cols:\n",
    "            chunk[col] = pd.to_numeric(chunk[col], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float_cols = ['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'installment',\n",
    "              'annual_inc', 'dti', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n",
    "              'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', \n",
    "              'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', \n",
    "              'last_pymnt_amnt']\n",
    "\n",
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000, usecols=float_cols)\n",
    "for chunk in chunk_iter:\n",
    "        for col in float_cols:\n",
    "            chunk[col] = pd.to_numeric(chunk[col], downcast='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have successfully converted all useful columns to their optimal types, it is time to put it all together. I will create a list with all necessary columns, then print the memory usage of all of the optimized columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Megabytes of total memory usage in each chunk:\n",
      "\n",
      "3.8584365844726562\n",
      "3.854074478149414\n",
      "3.8555965423583984\n",
      "3.857219696044922\n",
      "3.8547658920288086\n",
      "3.857466697692871\n",
      "3.8548221588134766\n",
      "3.8573246002197266\n",
      "3.8569259643554688\n",
      "3.8569107055664062\n",
      "3.8556394577026367\n",
      "3.853343963623047\n",
      "3.858841896057129\n",
      "3.9395370483398438\n",
      "0.7084341049194336\n",
      "\n",
      "Total memory usage across all chunks:\n",
      "54.77933979034424\n"
     ]
    }
   ],
   "source": [
    "all_useful_cols = []\n",
    "for col in useful_cols:\n",
    "    all_useful_cols.append(col)\n",
    "for col in int_cols:\n",
    "    all_useful_cols.append(col)\n",
    "for col in float_cols:\n",
    "    all_useful_cols.append(col)\n",
    "\n",
    "chunk_iter = pd.read_csv('loans_2007.csv', chunksize=3000, usecols=all_useful_cols)\n",
    "list_mem = []\n",
    "print(\"Megabytes of total memory usage in each chunk:\\n\")\n",
    "for chunk in chunk_iter:\n",
    "    mem_bytes = chunk.memory_usage(deep=True).sum()\n",
    "    mem_megabytes = mem_bytes/(2**20)\n",
    "    print(mem_megabytes)\n",
    "    list_mem.append(mem_megabytes)\n",
    "\n",
    "print(\"\\nTotal memory usage across all chunks:\")\n",
    "print(sum(list_mem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of converting float columns\n",
    "\n",
    "I have determined that the amount of memory needed for all columns will decrease by over 10 megabytes when all of the columns are optimized. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
